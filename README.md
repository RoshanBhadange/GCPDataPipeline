# GCPDataPipeline

1. Source files ingestion into GCS

2. ETL using DataProc

Spark job to load data into hive tables, python

3. Creating DW in google bigquery

Dim and fact tables 

4. Job Scheduling using Airflow 

Job schedule,monitoring and workflows

